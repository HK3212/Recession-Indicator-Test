{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Economical Indicators for Recession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recession Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Examining OECD CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#X feature data: Standardized confidence economic indicators showing economic growth or decay\n",
    "econ_data=pd.read_csv('CLI_Data.csv')\n",
    "#Y label data: Recession data for US\n",
    "rec_data=pd.read_csv('USREC.csv')\n",
    "\n",
    "#Find and store data for United States\n",
    "filter_us = econ_data.Country.str.contains(\"United States\")\n",
    "#Extract CCI values from the data\n",
    "filter_cci = econ_data.SUBJECT.str.contains(\"CSCICP03\")\n",
    "\n",
    "us_data = econ_data[filter_us]\n",
    "cci_data = us_data[filter_cci]\n",
    "\n",
    "#Use 75% of data for training; 25% for testing\n",
    "training_size = 0.75\n",
    "\n",
    "X_cci = cci_data.loc[:, 'Value'].values\n",
    "Y = rec_data.iloc[:, :2].values\n",
    "\n",
    "#Remove data before 1970 so X and Y match\n",
    "index = 0\n",
    "for val in Y:\n",
    "    year = val[0].split(\"-\")[0]\n",
    "    if year == '1970':\n",
    "        break\n",
    "    index += 1\n",
    "Y = Y[index:]\n",
    "\n",
    "#Remove dates from Y data\n",
    "Y = Y[:,1:]\n",
    "Y = Y.reshape(Y.shape[0])\n",
    "Y = Y.astype('int')\n",
    "X = X_cci.reshape(-1, 1)\n",
    "\n",
    "x_train = X[:int(len(X)*training_size)]\n",
    "y_train = Y[:int(len(Y)*training_size)]\n",
    "x_test = X[int(len(X)*training_size):]\n",
    "y_test = Y[int(len(Y)*training_size):]\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Logistic Regression to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification accuracy: 0.92\n",
      "[[122  10]\n",
      " [  2  16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_predict = logreg.predict(x_test)\n",
    "\n",
    "print(\"Logistic Regression classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Support Vector Machines on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine classification accuracy: 0.94\n",
      "[[126   6]\n",
      " [  3  15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm = SVC(gamma='scale', kernel='linear')\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Support Vector Machine classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Unemployment Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X feature data: Unemployment rates from Jan 1970 to Nov 2019\n",
    "unemp_data=pd.read_csv('OECD_Unemployment_Rate.csv')\n",
    "#Y label data: Recession indicators for Canada\n",
    "canrec_data=pd.read_csv('CANREC.csv')\n",
    "\n",
    "#Find and store data for United States and Canada\n",
    "filterunemp_us = unemp_data.LOCATION.str.contains(\"USA\")\n",
    "filterunemp_can = unemp_data.LOCATION.str.contains(\"CAN\")\n",
    "\n",
    "unempus_data = unemp_data[filterunemp_us]\n",
    "unempcan_data = unemp_data[filterunemp_can]\n",
    "\n",
    "#Extracting and storing unemploying rate values for US and Canada\n",
    "X_usunemp = unempus_data.loc[:, 'Value'].values\n",
    "X_can = unempcan_data.loc[:, 'Value'].values\n",
    "\n",
    "#Remove Last entry from canada unemployment data so data sets match\n",
    "X_can = X_can[:-1]\n",
    "\n",
    "X_us = X_usunemp.reshape(-1, 1)\n",
    "X_can = X_can.reshape(-1, 1)\n",
    "\n",
    "#Use 75% of data for training; 25% for testing\n",
    "training_size = 0.75\n",
    "\n",
    "x_train = X_us[:int(len(X_us)*training_size)]\n",
    "x_test = X_us[int(len(X_us)*training_size):]\n",
    "y_train = Y[:int(len(Y)*training_size)]\n",
    "y_test = Y[int(len(Y)*training_size):]\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Logistic Regression to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification accuracy: 0.88\n",
      "[[132   0]\n",
      " [ 18   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_predict = logreg.predict(x_test)\n",
    "\n",
    "print(\"Logistic Regression classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Support Vector Machine to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine classification accuracy: 0.88\n",
      "[[132   0]\n",
      " [ 18   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm = SVC(gamma='scale',  kernel='linear')\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Support Vector Machine classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions on Canada Recession Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification accuracy: 0.5066666666666667\n",
      "[[76  0]\n",
      " [74  0]]\n",
      "Support Vector Machine classification accuracy: 0.5066666666666667\n",
      "[[76  0]\n",
      " [74  0]]\n"
     ]
    }
   ],
   "source": [
    "Y_can = canrec_data.iloc[:, :2].values\n",
    "\n",
    "#Remove data before 1970 so X and Y match\n",
    "index = 0\n",
    "for val in Y_can:\n",
    "    year = val[0].split(\"-\")[0]\n",
    "    if year == '1970':\n",
    "        break\n",
    "    index += 1\n",
    "Y_can = Y_can[index:]\n",
    "\n",
    "#Remove dates from Y data\n",
    "Y_can = Y_can[:,1:]\n",
    "Y_can = Y_can.reshape(Y_can.shape[0])\n",
    "Y_can = Y_can.astype('int')\n",
    "\n",
    "#Use 75% of data for training; 25% for testing\n",
    "training_size = 0.75\n",
    "\n",
    "x_train = X_can[:int(len(X_can)*training_size)]\n",
    "y_train = Y_can[:int(len(Y_can)*training_size)]\n",
    "x_test = X_can[int(len(X_can)*training_size):]\n",
    "y_test = Y_can[int(len(Y_can)*training_size):]\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "#Apply Logistic Regression to Canada Unemployment data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_predict = logreg.predict(x_test)\n",
    "\n",
    "print(\"Logistic Regression classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)\n",
    "\n",
    "#Apply SVM to Canada Unemployment data\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm = SVC(gamma='scale', kernel='linear')\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Support Vector Machine classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C:  Interest Rate Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X feature data: US 10-Year Treasury Constant Maturity Minus Federal Funds Rate\n",
    "yield_data=pd.read_csv('Ten_Year_Treasury_Maturity.csv')\n",
    "\n",
    "X_yield = yield_data.loc[:, 'T10YFF'].values\n",
    "X = X_yield.reshape(-1, 1)\n",
    "\n",
    "#Use 75% of data for training; 25% for testing\n",
    "training_size = 0.75\n",
    "x_train = X[:int(len(X)*training_size)]\n",
    "y_train = Y[:int(len(Y)*training_size)]\n",
    "x_test = X[int(len(X)*training_size):]\n",
    "y_test = Y[int(len(Y)*training_size):]\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Logistic Regression to Yield Curve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification accuracy: 0.88\n",
      "[[132   0]\n",
      " [ 18   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_predict = logreg.predict(x_test)\n",
    "\n",
    "print(\"Logistic Regression classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Support Vector Machine to Yield Curve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine classification accuracy: 0.88\n",
      "[[132   0]\n",
      " [ 18   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm = SVC(gamma='scale', kernel='linear')\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Support Vector Machine classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Examining OECD BCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "filter_bci = econ_data.SUBJECT.str.contains(\"BSCICP03\")\n",
    "bci_data = us_data[filter_bci]\n",
    "\n",
    "X_bci = bci_data.loc[:, 'Value'].values\n",
    "X = X_bci.reshape(-1, 1)\n",
    "\n",
    "#Use 75% of data for training; 25% for testing\n",
    "training_size = 0.75\n",
    "x_train = X[:int(len(X)*training_size)]\n",
    "y_train = Y[:int(len(Y)*training_size)]\n",
    "x_test = X[int(len(X)*training_size):]\n",
    "y_test = Y[int(len(Y)*training_size):]\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Logistic Regression to BCI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification accuracy: 0.9333333333333333\n",
      "[[132   0]\n",
      " [ 10   8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_predict = logreg.predict(x_test)\n",
    "\n",
    "print(\"Logistic Regression classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Support Vector Machine to BCI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine classification accuracy: 0.9333333333333333\n",
      "[[132   0]\n",
      " [ 10   8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm = SVC(gamma='scale', kernel='linear')\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Support Vector Machine classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Making a Predictive Model with all Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Want to store all indicator data investigated so far into set of training data\n",
    "X_cci = X_cci.reshape(X_cci.shape[0])\n",
    "X_usunemp = X_usunemp.reshape(X_usunemp.shape[0])\n",
    "X_yield = X_yield.reshape(X_yield.shape[0])\n",
    "X_bci = X_bci.reshape(X_bci.shape[0])\n",
    "\n",
    "feature_data = [X_cci, X_usunemp,  X_yield, X_bci]\n",
    "\n",
    "feature_data = np.stack(feature_data, axis=1)\n",
    "\n",
    "#Use 75% of data for training; 25% for testing\n",
    "training_size = 0.75\n",
    "x_train = feature_data[:int(len(feature_data)*training_size)]\n",
    "y_train = Y[:int(len(Y)*training_size)]\n",
    "x_test = feature_data[int(len(feature_data)*training_size):]\n",
    "y_test = Y[int(len(Y)*training_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Support Vector Machine to Indicator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine classification accuracy: 0.9733333333333334\n",
      "[[130   2]\n",
      " [  2  16]]\n"
     ]
    }
   ],
   "source": [
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm = SVC(gamma='scale', kernel='linear')\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Support Vector Machine classification accuracy: \" + str(accuracy_score(y_test, y_predict)))\n",
    "\n",
    "confmatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confmatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
